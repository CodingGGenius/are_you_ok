{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87405c1c-b4eb-4bf8-955b-fab75cfd03fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Using GPU device\n"
     ]
    }
   ],
   "source": [
    "import tkinter.ttk as ttk\n",
    "import tkinter.messagebox as msgbox\n",
    "import tkinter as tk\n",
    "import cv2 \n",
    "import datetime\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter import scrolledtext\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import ntpath\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "right_arm_model = load_model('./models/right_arm_model.h5')\n",
    "left_arm_model = load_model('./models/left_arm_model.h5')\n",
    "right_leg_model = load_model('./models/right_leg_model.h5')\n",
    "left_leg_model = load_model('./models/left_leg_model.h5')\n",
    "\n",
    "device = \"gpu\" # please change it to \"gpu\" if the model needs to be run on cuda.\n",
    "\n",
    "protoFile = \"./models/pose_deploy_linevec.prototxt\"\n",
    "weightsFile = \"./models/pose_iter_440000.caffemodel\"\n",
    "nPoints = 18\n",
    "# COCO Output Format\n",
    "keypointsMapping = ['Nose', 'Neck', 'R-Sho', 'R-Elb', 'R-Wr', 'L-Sho', \n",
    "                    'L-Elb', 'L-Wr', 'R-Hip', 'R-Knee', 'R-Ank', 'L-Hip', \n",
    "                    'L-Knee', 'L-Ank', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n",
    "\n",
    "POSE_PAIRS = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],\n",
    "              [1,8], [8,9], [9,10], [1,11], [11,12], [12,13],\n",
    "              [1,0], [0,14], [14,16], [0,15], [15,17],\n",
    "              [2,17], [5,16] ]\n",
    "\n",
    "# index of pafs correspoding to the POSE_PAIRS\n",
    "# e.g for POSE_PAIR(1,2), the PAFs are located at indices (31,32) of output, Similarly, (1,5) -> (39,40) and so on.\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], \n",
    "          [19,20], [21,22], [23,24], [25,26], [27,28], [29,30], \n",
    "          [47,48], [49,50], [53,54], [51,52], [55,56], \n",
    "          [37,38], [45,46]]\n",
    "\n",
    "colors = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],\n",
    "         [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],\n",
    "         [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "if device == \"cpu\":\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "    print(\"Using CPU device\")\n",
    "elif device == \"gpu\":\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "    print(\"Using GPU device\")\n",
    "\n",
    "# Find the Keypoints using Non Maximum Suppression on the Confidence Map\n",
    "def getKeypoints(probMap, threshold=0.1):\n",
    "    \n",
    "    mapSmooth = cv2.GaussianBlur(probMap,(3,3),0,0)\n",
    "\n",
    "    mapMask = np.uint8(mapSmooth>threshold)\n",
    "    keypoints = []\n",
    "    \n",
    "    #find the blobs\n",
    "    contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #for each blob find the maxima\n",
    "    for cnt in contours:\n",
    "        blobMask = np.zeros(mapMask.shape)\n",
    "        blobMask = cv2.fillConvexPoly(blobMask, cnt, 1)\n",
    "        maskedProbMap = mapSmooth * blobMask\n",
    "        _, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap)\n",
    "        keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],))\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "# Find valid connections between the different joints of a all persons present\n",
    "def getValidPairs(output, frameWidth, frameHeight, detected_keypoints):\n",
    "    valid_pairs = []\n",
    "    invalid_pairs = []\n",
    "    n_interp_samples = 10\n",
    "    paf_score_th = 0.1\n",
    "    conf_th = 0.7\n",
    "    # loop for every POSE_PAIR\n",
    "    for k in range(len(mapIdx)):\n",
    "        # A->B constitute a limb\n",
    "        pafA = output[0, mapIdx[k][0], :, :]\n",
    "        pafB = output[0, mapIdx[k][1], :, :]\n",
    "        pafA = cv2.resize(pafA, (frameWidth, frameHeight))\n",
    "        pafB = cv2.resize(pafB, (frameWidth, frameHeight))\n",
    "\n",
    "        # Find the keypoints for the first and second limb\n",
    "        candA = detected_keypoints[POSE_PAIRS[k][0]]\n",
    "        candB = detected_keypoints[POSE_PAIRS[k][1]]\n",
    "        nA = len(candA)\n",
    "        nB = len(candB)\n",
    "\n",
    "        # If keypoints for the joint-pair is detected\n",
    "        # check every joint in candA with every joint in candB \n",
    "        # Calculate the distance vector between the two joints\n",
    "        # Find the PAF values at a set of interpolated points between the joints\n",
    "        # Use the above formula to compute a score to mark the connection valid\n",
    "        \n",
    "        if( nA != 0 and nB != 0):\n",
    "            valid_pair = np.zeros((0,3))\n",
    "            for i in range(nA):\n",
    "                max_j=-1\n",
    "                maxScore = -1\n",
    "                found = 0\n",
    "                for j in range(nB):\n",
    "                    # Find d_ij\n",
    "                    d_ij = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                    norm = np.linalg.norm(d_ij)\n",
    "                    if norm:\n",
    "                        d_ij = d_ij / norm\n",
    "                    else:\n",
    "                        continue\n",
    "                    # Find p(u)\n",
    "                    interp_coord = list(zip(np.linspace(candA[i][0], candB[j][0], num=n_interp_samples),\n",
    "                                            np.linspace(candA[i][1], candB[j][1], num=n_interp_samples)))\n",
    "                    # Find L(p(u))\n",
    "                    paf_interp = []\n",
    "                    for k in range(len(interp_coord)):\n",
    "                        paf_interp.append([pafA[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))],\n",
    "                                           pafB[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))] ]) \n",
    "                    # Find E\n",
    "                    paf_scores = np.dot(paf_interp, d_ij)\n",
    "                    avg_paf_score = sum(paf_scores)/len(paf_scores)\n",
    "                    \n",
    "                    # Check if the connection is valid\n",
    "                    # If the fraction of interpolated vectors aligned with PAF is higher then threshold -> Valid Pair  \n",
    "                    if ( len(np.where(paf_scores > paf_score_th)[0]) / n_interp_samples ) > conf_th :\n",
    "                        if avg_paf_score > maxScore:\n",
    "                            max_j = j\n",
    "                            maxScore = avg_paf_score\n",
    "                            found = 1\n",
    "                # Append the connection to the list\n",
    "                if found:            \n",
    "                    valid_pair = np.append(valid_pair, [[candA[i][3], candB[max_j][3], maxScore]], axis=0)\n",
    "\n",
    "            # Append the detected connections to the global list\n",
    "            valid_pairs.append(valid_pair)\n",
    "        else: # If no keypoints are detected\n",
    "#             print(\"No Connection : k = {}\".format(k))\n",
    "            invalid_pairs.append(k)\n",
    "            valid_pairs.append([])\n",
    "#     print(valid_pairs)\n",
    "    return valid_pairs, invalid_pairs\n",
    "\n",
    "# This function creates a list of keypoints belonging to each person\n",
    "# For each detected valid pair, it assigns the joint(s) to a person\n",
    "# It finds the person and index at which the joint should be added. This can be done since we have an id for each joint\n",
    "def getPersonwiseKeypoints(valid_pairs, invalid_pairs, keypoints_list):\n",
    "    # the last number in each row is the overall score \n",
    "    personwiseKeypoints = -1 * np.ones((0, 19))\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "        if k not in invalid_pairs:\n",
    "            partAs = valid_pairs[k][:,0]\n",
    "            partBs = valid_pairs[k][:,1]\n",
    "            indexA, indexB = np.array(POSE_PAIRS[k])\n",
    "\n",
    "            for i in range(len(valid_pairs[k])): \n",
    "                found = 0\n",
    "                person_idx = -1\n",
    "                for j in range(len(personwiseKeypoints)):\n",
    "                    if personwiseKeypoints[j][indexA] == partAs[i]:\n",
    "                        person_idx = j\n",
    "                        found = 1\n",
    "                        break\n",
    "\n",
    "                if found:\n",
    "                    personwiseKeypoints[person_idx][indexB] = partBs[i]\n",
    "                    personwiseKeypoints[person_idx][-1] += keypoints_list[partBs[i].astype(int), 2] + valid_pairs[k][i][2]\n",
    "\n",
    "                # if find no partA in the subset, create a new subset\n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(19)\n",
    "                    row[indexA] = partAs[i]\n",
    "                    row[indexB] = partBs[i]\n",
    "                    # add the keypoint_scores for the two keypoints and the paf_score \n",
    "                    row[-1] = sum(keypoints_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2]\n",
    "                    personwiseKeypoints = np.vstack([personwiseKeypoints, row])\n",
    "    return personwiseKeypoints\n",
    "\n",
    "def pred_multiple_onvideo(video_path, filename):\n",
    "    if video_path == 'cam':\n",
    "        cap = cv2.VideoCapture(int(filename))\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        print(video_path)\n",
    "    data = []\n",
    "    position = []\n",
    "    last_position = []\n",
    "    final_position_index = -1\n",
    "    detected_humans = [] #[human][index, part_seq, part_nan_count, part_action, count]\n",
    "    \n",
    "    ret, image1 = cap.read()\n",
    "    while cap.isOpened():\n",
    "        t0 = cv2.getTickCount()\n",
    "        if ret == False:\n",
    "            break\n",
    "            \n",
    "        frameWidth = image1.shape[1]\n",
    "        frameHeight = image1.shape[0]\n",
    "\n",
    "        # Fix the input Height and get the width according to the Aspect Ratio\n",
    "        inHeight = 368 #인식에 문제가 있다면 이 값을 크게 조절하세요 (max = videofile height)\n",
    "        inWidth = int((inHeight/frameHeight)*frameWidth)\n",
    "        inpBlob = cv2.dnn.blobFromImage(image1, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "        net.setInput(inpBlob)\n",
    "        output = net.forward()\n",
    "\n",
    "        i = 0\n",
    "        probMap = output[0, i, :, :]\n",
    "        probMap = cv2.resize(probMap, (frameWidth, frameHeight))\n",
    "\n",
    "        detected_keypoints = []\n",
    "        keypoints_list = np.zeros((0,3))\n",
    "        keypoint_id = 0\n",
    "        threshold = 0.1\n",
    "\n",
    "        for part in range(nPoints):\n",
    "            probMap = output[0,part,:,:]\n",
    "            probMap = cv2.resize(probMap, (image1.shape[1], image1.shape[0]))\n",
    "            keypoints = getKeypoints(probMap, threshold)\n",
    "            keypoints_with_id = []\n",
    "            for i in range(len(keypoints)):\n",
    "                keypoints_with_id.append(keypoints[i] + (keypoint_id,))\n",
    "                keypoints_list = np.vstack([keypoints_list, keypoints[i]])\n",
    "                keypoint_id += 1\n",
    "\n",
    "            detected_keypoints.append(keypoints_with_id)\n",
    "\n",
    "        valid_pairs, invalid_pairs = getValidPairs(output, frameWidth, frameHeight, detected_keypoints)\n",
    "        personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs, keypoints_list)\n",
    "        \n",
    "        \n",
    "        #사람 구분\n",
    "        detected_Obj = []\n",
    "        last_position += position\n",
    "        position = []\n",
    "        keylist = np.empty((len(personwiseKeypoints), 13, 2))\n",
    "\n",
    "        for i in range(1, 14):\n",
    "            for n in range(len(personwiseKeypoints)):\n",
    "                index = personwiseKeypoints[n][np.array(POSE_PAIRS[i])]\n",
    "                if -1 in index:\n",
    "                    continue\n",
    "                A = np.int32(keypoints_list[personwiseKeypoints[n][i].astype(int)])\n",
    "                keylist[n][i - 1] = A[:-1] #keylist는 목부터 발까지 좌표 값만 저장됨\n",
    "\n",
    "        for n in range(len(personwiseKeypoints)):\n",
    "            short_distance = 10000\n",
    "            if int(keylist[n][0][0]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                #여기서 벡터값 계산\n",
    "                joint = np.empty((13, 2))\n",
    "                for j in range(13):\n",
    "                    try:\n",
    "                        joint[j] = [keylist[n][j][0], keylist[n][j][1]]\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # Compute angles between joints\n",
    "                v1 = joint[[0, 1, 2, 0, 4, 5, 0, 7, 8, 0, 10, 11], :2] # Parent joint\n",
    "                v2 = joint[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], :2] # Child joint\n",
    "                v = v2 - v1 # [12, 2]\n",
    "                # Normalize v\n",
    "                v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "                # Get angle using arcos of dot product\n",
    "                angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                    v[[0, 1, 3, 4, 6, 7, 9, 10],:], \n",
    "                    v[[1, 2, 4, 5, 7, 8, 10, 11],:]))\n",
    "\n",
    "                angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "                angle_label = np.array([angle], dtype=np.float32)\n",
    "\n",
    "                count = -1\n",
    "                last_p_index = -1\n",
    "                short_p_index = -1\n",
    "                for last_p in range(len(last_position)):\n",
    "                    temp_x = keylist[n][0][0] - last_position[last_p][0]\n",
    "                    temp_y = keylist[n][0][1] - last_position[last_p][1]\n",
    "                    temp_distance = temp_x * temp_x + temp_y * temp_y\n",
    "                    if temp_distance < short_distance:\n",
    "                        short_distance = temp_distance\n",
    "                        last_p_index = last_p\n",
    "                        position_index = last_position[last_p][2]\n",
    "                        \n",
    "                if last_p_index == -1: #전 프레임에 같은 사람이 없을때\n",
    "                    final_position_index+=1\n",
    "                    position.append([keylist[n][0][0], keylist[n][0][1], final_position_index, 0])\n",
    "                    \n",
    "                    for detect_seq in detected_humans: #사람이 전 프레임에 있던 사람인지 확인\n",
    "                        if final_position_index == detect_seq[0]: #해당 인덱스의 사람이 존재하는지 검사\n",
    "                            detected_humans.append([final_position_index, [], 0, 0, [], 0, 0, [], 0, 0, [], 0, 0])\n",
    "                            pred_raw_part(angle_label, detected_humans[-1])\n",
    "\n",
    "                else: #전 프레임에 같은 사람이 있을때\n",
    "                    for detect_seq in detected_humans: #사람이 전 프레임에 있던 사람인지 확인\n",
    "                        if position_index == detect_seq[0]: #해당 인덱스의 사람이 존재하는지 검사\n",
    "                            position.append([keylist[n][0][0], keylist[n][0][1], position_index, 0])\n",
    "                            del last_position[last_p_index]\n",
    "                            pred_raw_part(angle_label, detect_seq)        \n",
    "\n",
    "        del_list = []         \n",
    "        for gone in range(len(last_position)):\n",
    "            last_position[gone][3] += 1\n",
    "            if last_position[gone][3] > 10:\n",
    "                del_list.append(last_position[gone])\n",
    "                \n",
    "\n",
    "        if len(del_list) > 0:\n",
    "            for del_position in range(len(del_list)):\n",
    "                for del_index in detected_humans:\n",
    "                    if del_index[0] == del_list[del_position]:\n",
    "                        last_position.remove(del_list[del_position])\n",
    "                        detected_humans.remove(del_index)\n",
    "                        break\n",
    "\n",
    "def pred_raw_part(object_n, human_seq):\n",
    "    object_n = object_n[:-1]\n",
    "    seq_length = 30\n",
    "\n",
    "    actions = ['assult', 'normal']\n",
    "    \n",
    "    nan_skip_count = 10 #오차 허용 프레임\n",
    "    \n",
    "    for process_count in range(4):\n",
    "        human_seq[process_count * 3 + 2] = take_not_nan(object_n[process_count * 2], object_n[process_count * 2 + 1], human_seq[process_count * 3 + 1], human_seq[process_count * 3 + 2])\n",
    "        \n",
    "    for process_count in range(4):\n",
    "        if human_seq[process_count * 3 + 2] == 15:\n",
    "            human_seq[process_count * 3 + 1] = []\n",
    "            human_seq[process_count * 3 + 3] = 0\n",
    "            \n",
    "    for process_count, model in enumerate([right_arm_model, left_arm_model, right_leg_model, left_leg_model]):\n",
    "        human_seq[process_count * 3 + 3] = pred_part(human_seq[process_count * 3 + 1], human_seq[process_count * 3 + 2], model, human_seq[process_count * 3 + 3])\n",
    "        \n",
    "def take_not_nan(key1, key2, part_seq, part_nan):\n",
    "    if not np.isnan(key1) and not np.isnan(key2):\n",
    "        part_seq.append([key1, key2])\n",
    "        return 0\n",
    "    else:\n",
    "        part_nan += 1\n",
    "        if part_nan > 10: #오차 허용 프레임\n",
    "            return 15\n",
    "        else:\n",
    "            return part_nan\n",
    "        \n",
    "def pred_part(part_seq, part_nan, part_model, part_action):\n",
    "    seq_length = 30\n",
    "    if len(part_seq) > seq_length and part_nan == 0:\n",
    "        input_data = np.expand_dims(np.array(part_seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "        y_pred = part_model.predict(input_data).squeeze()\n",
    "\n",
    "        i_pred = int(np.argmax(y_pred))\n",
    "        conf = y_pred[i_pred]\n",
    "\n",
    "        if conf > 0.5 and i_pred == 0: #신뢰도\n",
    "            part_action += 1\n",
    "            print(part_action)\n",
    "            if part_action > 2:\n",
    "                list_txt.append(('Detect Assult at ', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), ' ',  conf, '%'))\n",
    "            with open(\"./human_problem.txt\") as f:\n",
    "                f.writelines(lines)\n",
    "            \n",
    "            return part_action\n",
    "        else:\n",
    "            return 0\n",
    "    return part_action\n",
    "\n",
    "def video_start(list_file, video_name):\n",
    "    list_txt=[]\n",
    "    pred_multiple_onvideo(list_file, video_name)\n",
    "\n",
    "    \n",
    "root = tk.Tk()\n",
    "root.title(\"Are You OK?\")\n",
    "root.geometry(\"640x640+100+300\")\n",
    "\n",
    "video_file_list = []\n",
    "\n",
    "# 파일추가\n",
    "def add_file():\n",
    "    file = filedialog.askopenfilenames(title=\"동영상 파일을 선택하세요.\",\n",
    "                                       filetypes=(\n",
    "                                           (\"MOV 파일\", \"*.mov *.mp4\"), (\"모든 파일\", \"*.*\")),\n",
    "                                       initialdir=\"C:/\")  # \"C:/\"\n",
    "        \n",
    "    # 사용자가 선택한 파일 목록\n",
    "    for file in file:\n",
    "        video_file_list.append(file)\n",
    "        list_file.insert(END, file)\n",
    "\n",
    "# 선택삭제\n",
    "def del_file():\n",
    "    for index in reversed(list_file.curselection()):\n",
    "        list_file.delete(index)\n",
    "\n",
    "\n",
    "# 시작\n",
    "def start():\n",
    "    # 카메라 확인(카메라.파일 둘 중 하나만 가능하도록), log 출력시키기\n",
    "    start_state = 0\n",
    "    for find_cam in video_file_list:\n",
    "        if 'cam' in find_cam[:-1]:\n",
    "            video_start('cam', find_cam[-1:])\n",
    "            start_state = 1\n",
    "            \n",
    "    if start_state == 0:\n",
    "        for list_file in video_file_list:\n",
    "            video_start(list_file, ntpath.basename(list_file))\n",
    "    \n",
    "    # 파일 목록 확인\n",
    "    if len(video_file_list) == 0:\n",
    "        msgbox.showwarning(\"경고\", \"동영상 파일을 추가하세요.\")\n",
    "        return\n",
    "\n",
    "def load_log():\n",
    "    tf = open(\"./human_problem.txt\", 'r', encoding=\"UTF-8\")\n",
    "    data = tf.read()\n",
    "    log_text.insert(END, data)\n",
    "    tf.close()\n",
    "\n",
    "    \n",
    "\n",
    "# cam 선택 (5번까지)\n",
    "def select_cam():\n",
    "    for i in range(5):\n",
    "        cap = cv2.VideoCapture(i)\n",
    "        ret, image1 = cap.read()\n",
    "        if ret:\n",
    "            msgbox.showinfo(\"정보\", \"성공적으로 카메라가 연결되었습니다.\")\n",
    "            list_file.insert(END, 'cam' + str(i))\n",
    "            video_file_list.append('cam' + str(i))\n",
    "            return\n",
    "    msgbox.showerror(\"경고\", \"내·외장 카메라가 인식되지 않습니다.\")\n",
    "    return\n",
    "\n",
    "\n",
    "# (카메라)장치 프레임\n",
    "cam_frame = Frame(root)\n",
    "cam_frame.pack(fill=\"x\", padx=5, pady=5)\n",
    "\n",
    "btn_select_cam = Button(cam_frame, padx=5, pady=5,\n",
    "                        width=12, text=\"카메라 선택\", command=select_cam)\n",
    "btn_select_cam.pack(side=\"left\")\n",
    "\n",
    "# 파일 첨부 프레임\n",
    "file_frame = Frame(root)\n",
    "file_frame.pack(fill=\"x\", padx=5, pady=5)\n",
    "\n",
    "btn_add_file = Button(file_frame, padx=5, pady=5,\n",
    "                      width=12, text=\"파일추가\", command=add_file)\n",
    "btn_add_file.pack(side=\"left\")\n",
    "\n",
    "btn_del_file = Button(file_frame, padx=5, pady=5,\n",
    "                      width=12, text=\"선택삭제\", command=del_file)\n",
    "btn_del_file.pack(side=\"right\")\n",
    "\n",
    "\n",
    "# 파일 리스트 프레임\n",
    "list_frame = LabelFrame(root, text=\"파일 경로 목록\")\n",
    "list_frame.pack(fill=\"both\", padx=5, pady=5)\n",
    "\n",
    "scrollbar = Scrollbar(list_frame)\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "list_file = Listbox(list_frame, selectmode=\"extended\",\n",
    "                    height=5, yscrollcommand=scrollbar.set)\n",
    "list_file.pack(side=\"left\", fill=\"both\", expand=True, padx=5, pady=5)\n",
    "scrollbar.config(command=list_file.yview)\n",
    "\n",
    "\n",
    "# 파일 저장 경로 프레임\n",
    "\n",
    "# 분석값 텍스트 박스 프레임(log값을 반환)\n",
    "log_frame = LabelFrame(root, text=\"log값\")\n",
    "log_frame.pack(fill=\"both\", padx=5, pady=5)\n",
    "\n",
    "scrol_w = 85\n",
    "scrol_h = 20\n",
    "\n",
    "log = open(\"./human_problem.txt\", 'r') #, encoding=\"UTF-8\"\n",
    "\n",
    "log_text = scrolledtext.ScrolledText(log_frame, width=scrol_w, height=scrol_h, wrap=tk.WORD)  # wrap = tk.WORD - 단어단위 줄바꿈  지정\n",
    "log_text.grid(column=0, columnspan=10)\n",
    "\n",
    "log_data=log.read()\n",
    "log_text.insert(tk.INSERT, log_data)\n",
    "log_text.configure(state=\"disabled\")\n",
    "\n",
    "# 실행 프레임\n",
    "frame_run = Frame(root)\n",
    "frame_run.pack(fill=\"x\", padx=5, pady=5)\n",
    "\n",
    "btn_close = Button(frame_run, padx=5, pady=5, text=\"닫기\",\n",
    "                   width=12, command=root.destroy)\n",
    "btn_close.pack(side=\"right\", padx=5, pady=5)\n",
    "\n",
    "btn_start = Button(frame_run, padx=5, pady=5,\n",
    "                   text=\"시작\", width=12, command=start)\n",
    "btn_start.pack(side=\"right\", padx=5, pady=5)\n",
    "\n",
    "root.resizable(False, False)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68d773-67a5-45ed-826a-6381762e2468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541234d5-14cc-4b2c-8071-8d4fc4712a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
